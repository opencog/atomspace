
                            Benchmarking Diary
                            ------------------

This file contains assorted benchmark results.  This is meant to be a
historical log: as changes to the atomspace are made, we can see how
performance changes over time.


26 March 2013
-------------
Benchamrks performed on 2008 vintage CPU and system:
   AMD Athlon(tm) 64 X2 Dual Core Processor 6000+
   3GHz  1024 KB cache
   8GB ECC DDR2 RAM

First, some raw data, and then some commentary & analysis.

The below measures the performance of the raw AtomTable interface:
    ./atomspace_bm -A -b -X     # Note the -X is uppercase!

    Benchmarking AtomSpace's addNode method 100000 times ..........
    0.664715 seconds elapsed (150440.40 per second)
    Sum clock() time for all requests: 390000 (0.39 seconds, 256410 requests per second)
    ------------------------------
    Benchmarking AtomSpace's addLink method 100000 times ..........
    0.784073 seconds elapsed (127539.17 per second)
    Sum clock() time for all requests: 580000 (0.58 seconds, 172414 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getType method 100000 times ..........
    0.138640 seconds elapsed (721291.70 per second)
    Sum clock() time for all requests: 40000 (0.04 seconds, 2.5e+06 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getTV method 100000 times ..........
    0.142129 seconds elapsed (703586.45 per second)
    Sum clock() time for all requests: 50000 (0.05 seconds, 2e+06 requests per second)
    ------------------------------
    Benchmarking AtomSpace's setTV method 100000 times ..........
    0.166353 seconds elapsed (601131.38 per second)
    Sum clock() time for all requests: 60000 (0.06 seconds, 1.66667e+06 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getHandleSet method 100000 times ..........
    46.604309 seconds elapsed (2145.72 per second)
    Sum clock() time for all requests: 46240000 (46.24 seconds, 2162.63 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getNodeHandles method 100000 times ..........
    3.733971 seconds elapsed (26781.14 per second)
    Sum clock() time for all requests: 3410000 (3.41 seconds, 29325.5 requests per second)
    ------------------------------


The below measures the performance of the AtomSpaceImpl interface:
    ./atomspace_bm -A -b -x     # Note the -x is lowercase!

    Benchmarking AtomSpace's addNode method 100000 times ..........
    4.878072 seconds elapsed (20499.90 per second)
    Sum clock() time for all requests: 3150000 (3.15 seconds, 31746 requests per second)
    ------------------------------
    Benchmarking AtomSpace's addLink method 100000 times ..........
    7.789448 seconds elapsed (12837.88 per second)
    Sum clock() time for all requests: 3990000 (3.99 seconds, 25062.7 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getType method 100000 times ..........
    3.509915 seconds elapsed (28490.72 per second)
    Sum clock() time for all requests: 120000 (0.12 seconds, 833333 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getTV method 100000 times ..........
    3.953390 seconds elapsed (25294.75 per second)
    Sum clock() time for all requests: 160000 (0.16 seconds, 625000 requests per second)
    ------------------------------
    Benchmarking AtomSpace's setTV method 100000 times ..........
    3.941879 seconds elapsed (25368.61 per second)
    Sum clock() time for all requests: 160000 (0.16 seconds, 625000 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getHandleSet method 100000 times ..........
    79.308176 seconds elapsed (1260.90 per second)
    Sum clock() time for all requests: 66550000 (66.55 seconds, 1502.63 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getNodeHandles method 100000 times ..........
    7.634395 seconds elapsed (13098.61 per second)
    Sum clock() time for all requests: 3830000 (3.83 seconds, 26109.7 requests per second)
    ------------------------------


The below measures the performance of the AtomSpace interface:
    ./atomspace_bm -A -b

    Benchmarking AtomSpace's addNode method 100000 times ..........
    5.710748 seconds elapsed (17510.84 per second)
    Sum clock() time for all requests: 3330000 (3.33 seconds, 30030 requests per second)
    ------------------------------
    Benchmarking AtomSpace's addLink method 100000 times ..........
    7.793599 seconds elapsed (12831.04 per second)
    Sum clock() time for all requests: 4110000 (4.11 seconds, 24330.9 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getType method 100000 times ..........
    7.581572 seconds elapsed (13189.88 per second)
    Sum clock() time for all requests: 3830000 (3.83 seconds, 26109.7 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getTV method 100000 times ..........
    6.203707 seconds elapsed (16119.39 per second)
    Sum clock() time for all requests: 2260000 (2.26 seconds, 44247.8 requests per second)
    ------------------------------
    Benchmarking AtomSpace's setTV method 100000 times ..........
    4.281147 seconds elapsed (23358.23 per second)
    Sum clock() time for all requests: 1570000 (1.57 seconds, 63694.3 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getHandleSet method 100000 times ..........
    81.959277 seconds elapsed (1220.12 per second)
    Sum clock() time for all requests: 77910000 (77.91 seconds, 1283.53 requests per second)
    ------------------------------
    Benchmarking AtomSpace's getNodeHandles method 100000 times ..........
    9.935555 seconds elapsed (10064.86 per second)
    Sum clock() time for all requests: 7270000 (7.27 seconds, 13755.2 requests per second)
    ------------------------------



Commentary and Analysis
-----------------------
The "raw AtomTable" numbers are what one gets if one uses just the
AtomTable, and naked pointers.  The AtomTable offers some indexes for
quick lookup of atoms by name, type, etc.  Getting atom attributes is
fast, as the atom table provides a direct pointer to the atom.

The AtomSpaceImpl interface is another "native" interface, but it hides
all raw pointers, and conducts all business by using handles.  Performance
is slower as a result.  We can estimate the overhead of this hiding by
comparing performance figures to the raw AtomTable results.

The AtomSpace interface attempts to provide thread safety by creating an
atomspace server, and communicating with it via request/response messages.
The server side itself uses the AtomSpaceImpl to do its work.  Again,
performance is slower.  Comparing to the AtomSpaceImpl numbers gives
a hint of the overhead of the request/response architecture.

Rearrange in tabular form:

   test            AtomTable    AtomSpaceImpl    AtomSpace
   name            K-ops/sec      K-ops/sec      K-ops/sec
   ----            ---------    -------------    ---------
  addNode            256.4         31.7            30.0
  addLink (***)      172.4         25.06           24.3
  getType           2500          833              26.1
  getTV             2000          625              44.2
  setTV             1666          625              63.7
  getHandleSet         2.16         1.50            1.28
  getNodeHandles      29.3         26.1            13.76


(***) See comment below

Clearly, raw access is much faster.  Clearly, the particular
getHandleSet (one of dozens) was slowww.

All operations were performed 100K times. To see how overheads actually
work, its easier to consider the microseconds per call.  No calculator
is necessary: just take the elapsed time (seconds) and multiply by 10
to get microseconds:

   test            AtomTable    AtomSpaceImpl    AtomSpace
   name            usecs/call     usecs/call     usecs/call
   ----            ---------    -------------    ---------
  addNode             3.9           31.5           33.3
  addLink (***)       5.8           39.9           41.1
  getType             0.4            1.2           38.3
  getTV               0.5            1.6           22.6
  setTV               0.6            1.6           15.7
  getHandleSet      462.4          665.5          779
  getNodeHandles     34.1           38.3           72.7

(***) See comment below

So...
The AtomSpaceImpl adds an aprox 30 usec overhead to addNode/addLink and
the client/server interface adds another 2 usecs

Its not clear why AtomSpaceImpl does NOT add an overhead to getType and
get/setTV ... instead, there seems to be a very hefty communications
overhead for this?  This doesn't make sense when compared to addNode/Link

It appears that both the AtomSpaceImpl, and the client/server design
add large overheads to the two handle-set gets. I assume this overhead
is because a lot of data is being moved around.

getNodeHandles is asking for nodes by name and type.  This is serviced
by the atom table, which maintains an index of these. (the NodeIndex)

getHandleSet asks for all atoms of a given type. Again, there is an
index in the AtomTable for this.  You'd think it should be faster;
I'm guessing that perhaps there is a lot of data copying going on here...

(***) The benchmark was broken, it was creating Links with an average
of 0.5 atoms in them, and a std deviation of 0.5. i.e. Most links had
one atoms in them; that's not typical. Thus, the reported numbers are
not realistic.


27 March 2013
-------------
Provided a new implementation for the getHandleSet that doubled
the performance. A major bottleneck was the generation of HandleEntry's
and then the copying of them into an std::vector.  Eliminating this
step saved a lot. See the template getHandleSet<OutputIterator> in
AtomTable.h for the right way to do these.

In fact, *all* HandleEntry things should be eliminated and replaced
by iterators, and should use std::copy_if instead of filterSet.

   test            AtomTable    AtomSpaceImpl    AtomSpace
   name            K-ops/sec      K-ops/sec      K-ops/sec
   ----            ---------    -------------    ---------
  getHandleSet-old     2.16         1.50            1.28
  getHandleSet-new     4.33         4.33            0.658


Basically, much/most of the overhead that AtomSpaceImpl adds to
the AtomTable is due to the copying of HandleSets into vectors
and such.


29 March 2013
-------------
Replaced more uses of HandleEntry with C++11 unordered_set and etc.
This improved performance across the board, except for setTV which
got a lot slower (!?) and getNodeHandles which got a little slower.
New results:

   test            AtomTable    AtomSpaceImpl    AtomSpace
   name            K-ops/sec      K-ops/sec      K-ops/sec
   ----            ---------    -------------    ---------
  addNode            270.3         28.5            33.2
  addLink            178.6         24.8            25.8
  getType           3333          833              33.0
  getTV             2000          714              60.6
  setTV             5000          666              44.4
  getHandleSet         4.99         4.27            2.83
  getNodeHandles      37.3         19.1            13.7
  getOutgoingSet    3333         1000              44.6


1 April 2013
-------------
Replaced all uses of HandleEntry with C++11 unordered_set and etc.
HandleEntry is now extinct.  The nature of the benchmark changed
as well: instead of creating 65536 atoms initially, the new bnechmark
creates 256K atoms: four times more than before. This has an overall
negative impact on addLink, getHandleSet and getNodeHandles.  However,
the new size is more realistic, so the actual perf is more realistic
too.

Added a no-op test. The no-op makes no calls to the atom-anything at
all.  Thus it provides a measuremnt baseline. Based on the no-op test,
we see that getType, getTV, setTV and getOutgoingSewt are running at
near-noop speeds.

Added scheme tests. The scheme tests create strings, and pass them to
the scheme interpreter.  The scheme interpreter is currently built on
top of the AtomSpace.  The scheme API does not currently expose the
getHandleSet and getNodeHandles API, so no measurements made for those.

New results:

   test           AtomTable    AtomSpaceImpl    AtomSpace    Scheme
   name           K-ops/sec      K-ops/sec      K-ops/sec   K-ops/sec
   ----           ---------    -------------    ---------   ---------
  noop             2500         2500            1250         2500
  addNode           333           97.1            30.1          5.10
  addLink            92.6         39.1            19.7          3.87
  getType          5000          769              76.3          3.90
  getTV            1429          769              45.5          4.53
  setTV            1429          667              47.2          2.30
  getHandleSet        1.12         1.11            0.742         -
  getNodeHandles     20.7         14.1            10.4           -
  getOutgoingSet   1666          909              50.5          2.78
  getIncomingSet   1111          476              75.8          1.82


Some comments about the scheme performance:
Measuring scheme performance the way it is currently measured is rather
misleading.  This is because the rate-limiting factor is the time it
takes to enter and exit the scheme interpreter.  Specifically, it seems
to take about 30 microseconds to call scm_with_guile() and about 110
microseconds to move from outside of scm_c_catch() to the inside, where
the C code for the atomspace is being called.  Thus, these two steps
alone rate-limit the measurement to 7K-ops/sec max.

In 'real life', both of these steps would be infrequent, as normally,
one would enter the interpeter, do a wholw lot of stuff, and then exit.
In other words, the correct way to measure performance for the scheme
bindings would be to create maybe 10 or 100 atoms, once one is 'inside'.

The above can be tested: grep for ONE_SHOT in the code.  It defines the
following loop, and then calls (crea 100)

(define (crea n)
  (if (not (eq? n 0))
    (let ()
      (cog-new-node 'ParseNode
        (string-join (list "stuff " (number->string n))))
      (crea (- n 1))
    )
  )
)

Thus, 100 nodes are created for just one entry into the interpreter.
The resulting create performance works out to be 11.7K creates/sec
which although is not stellar, clearly spends nearly half its time in
the atomspace, as opposed to the scheme code ... which is BTW no longer
trivial.  To conclude: the AtomSpace is a bottleneck, even for scheme.



27 March 2013
-------------

Rerun benchmarks:
Intel(R) Xeon(R)  X5650  @ 2.67GHz  12MB cache per core, 12 cores.
76GB RAM

1 October 2013
--------------
Remeasure, just for grins. Not expecting any change from above; hardware
is the same, compiler is gcc-4.7.4 instead of gcc 4.6.2 as above.

Surprisingly, there is a 20%-40% drop for addNode, addLink !!
Performance of getHandleSet halved!          Is this a compiler thing???
Performance of getNodeHandles is 5x faster!  Is this a compiler thing???
I think this change is compiler-related.


   test           AtomTable    AtomSpaceImpl    AtomSpace    Scheme
   name           K-ops/sec      K-ops/sec      K-ops/sec   K-ops/sec
   ----           ---------    -------------    ---------   ---------
  noop             1428
  addNode           222
  addLink            75.7
  getType          1429
  getTV            1429
  setTV            1666
  getHandleSet        0.693
  getNodeHandles    101
  getOutgoingSet   1111
  getIncomingSet   1000


9 October 2013
--------------
Remeasure. This is after removing most of the TLB, and using
std::shared_ptr atoms and handles.  This is a rather large
change, and I expect performance to be slightly degraded
(other changes needed for perf improvement haven't yet done).
The slowdown compared to above is almost surely due to the
more complex form that Handle now has, resulting in more copying.
(results in first column).


   test           AtomTable     AtomTable II      III          IV
   name           K-ops/sec      K-ops/sec      K-ops/sec   K-ops/sec
   ----           ---------     ----------      ---------   ---------
  noop            10000          3333           10000          inf
  addNode           208           238             222         204
  addLink            60.6          58.8            57.8        56.8
  getType          5000           833             833         769
  getTV             909          1000             909         666
  setTV             769           588             625         625
  getHandleSet        0.195         0.438           0.487       0.428
  getNodeHandles     83.3          91.7            80.0        91.7
  getOutgoingSet    625           833             909         769
  getIncomingSet   5000          1429            2000         909


The second column replaces Handle by UUID in the TypeIndex. This improves
performance by avoiding excess copying during handle manipulations.

Column III shows the profile after two significant changes: rejiggering
the way the AtomPtr is held by the handle, and by adding locks to the
AtomTable.  Looks like no change (the numbers are rather noisy).

Column IV shows the profile after a massive conversion to use std::shared_ptr
for truth values.


Repeat measurements for current code (IV) for all interfaces:

                   -A -X         -A -x            -A          -A -g
   test           AtomTable    AtomSpaceImpl    AtomSpace    Scheme
   name           K-ops/sec      K-ops/sec      K-ops/sec   K-ops/sec
   ----           ---------    -------------    ---------   ---------
  noop              inf         1111            1250         1250
  addNode           204           79.4            29.7          4.87
  addLink            56.8         31.4            18.9          4.90
  getType           769          357              32.7          4.36
  getTV             666          400              52.6          5.87
  setTV             625          400              51.3          3.64
  getHandleSet        0.428        0.420           0.187         -
  getNodeHandles     91.7         49.3            23.8           -
  getOutgoingSet    769          370              55.6          3.73
  getIncomingSet    909          434              52.6          2.29


Hmm. A net overall slowdown in AtomSpaceImpl. This is presumably due to
excessive pointer mainuplation (resulting in excess shared_ptr count
increments & ctor/dtor ops).

AtomSpace perf is neutral: some things got faster, some got slower.
Some didn't change. Unclear what that's about -- a mixed effect, I guess.

Curiously, Scheme perf improved across the board ... even when atomspace
perf went down. Perhaps this has to do with truth-value pointer managment?

--------------
Remeasure, after bugfix: WOW! WHAT A HUGE DIFFERENCE!
Removed a single line of code:

--- a/opencog/atomspace/AtomTable.h
+++ b/opencog/atomspace/AtomTable.h
@@ -685,7 +685,6 @@ public:
      * Return true if the atom table holds this handle, else return false.
      */
     bool holds(Handle h) const {
-        h = getHandle(h);
         return (NULL != h) and h->getAtomTable() == this;
     }

This was previously needed to resolve the shared_ptr for the handle.
It seems that the AtomSpace uses this holds() call a lot, and it was
paying a huge price for this (since resolution involved a search of
the indexes, among other things).  So remeasure:


                   -A -X         -A -x            -A          -A -g
   test           AtomTable    AtomSpaceImpl    AtomSpace    Scheme
   name           K-ops/sec      K-ops/sec      K-ops/sec   K-ops/sec
   ----           ---------    -------------    ---------   ---------
  noop              inf         2500            3333         3333
  addNode           204          156.0            69.4          6.46
  addLink            56.8         46.1            34.1          5.31
  getType           769          588             110            4.83
  getTV             666          556             238            8.13
  setTV             625          909             167            4.37
  getHandleSet        0.428        0.420           0.221         -
  getNodeHandles     91.7         82.6            50.7           -
  getOutgoingSet    769          476             204            4.87
  getIncomingSet    909          909             250            4.11


AtomSpaceImpl perf changes are neutral. Some things got faster, some got
slower. There's a huge amount of measurement noise; these numbers can be
hard to repeat (everything in this diary shows best of three).

AtomSpace perf: Wow! Huge improvement!

XXX FIXME: There seems to be a benchmark bug somewhere ... the AtomSpace
figures are high ONLY if I'm doing something else CPU intensive at the
same tie (e.g. compiling).  Even watching youtube helps a little, but not
as much. This alone reslts in a 2x or 3x performance improvement.
Theorize:
   -- Some cache or TLB effect, with other CPU causing different cache line
      alignments, thus avoiding contention.
   -- Some kerne context-swtiching effect: perhaps the clock() timer calls
      stall in the kernel, until some other context switch event forces
      a return?  Noop. Stub out the calls to clock(), but perf does not
      improve. (based on total elapsed time, which uses gettimeofday())
   -- Some kind of thread-dispatching effect: the AtomSpaceAsync threads
      stall. Perhaps a sched_yield() is needed in ASRequest?  No... tried
      that and it didn't work.
   -- It may still be a kernel-context wtiching thing; its just not
      cureable with sched_yield() or disabling clock()...

This is bad. It makes the measurements untrustworthy...

Plowing on anyway ... scheme and python, head-to-head.

                   -A -g          -A -c
   test            Scheme         Python
   name           K-ops/sec      K-ops/sec
   ----           ---------    -------------    ---------   ---------
  noop             3333          4000
  addNode             6.46          7.62
  addLink             5.31          6.32
  getType             4.83          7.30
  getTV               8.13          7.87
  setTV               4.37          7.40
  getHandleSet         -            0.057
  getNodeHandles       -            7.25
  getOutgoingSet      4.87          7.59
  getIncomingSet      4.11          7.68


Looks like the python bottleneck, whatever it is, dominates everything else.
Again: a 1.7x perf improvement when running a concurrent compile on other
CPU; without that, the python numbers would be in the 3.8-4.3 range.

Update: January 2015: Turns out the scheme bindings used a terrible
strategy for atom types, and for strings. Fixing this improved the
addNode performance by almost 2x and addLink by about 1.5x, with smaller
but significant improvements to the other methods.



27 October 2013
---------------
Remeasure after removing a variety of un-needed serialization code.
Summary: pretty much everything got faster for every layer.
 -- The AtomSpace API is now 2x to 5x faster than it was in March 2013
    when this diary was started.
 -- The AtomTable API is mostly 2x-3x slower than it was in March 2013
    Essentially all of this slow-down is attributable to the use of
    std::shared_ptr for memory management.  Perhaps someday, BoehmGC
    should be explored ...

                   -A -X         -A -x            -A          -A -g
   test           AtomTable    AtomSpaceImpl    AtomSpace    Scheme
   name           K-ops/sec      K-ops/sec      K-ops/sec   K-ops/sec
   ----           ---------    -------------    ---------   ---------
  noop             5000         5000            2000          inf
  addNode           208          147              68.0          8.93
  addLink            55.2         46.7            37.4          7.52
  getType          1111          588             588            7.58
  getTV             769          476             250            6.37
  setTV             714          435             213            7.63
  getHandleSet        0.440        0.424           0.265         -
  getNodeHandles     82.6         84.0            56.8           -
  getOutgoingSet    666          500             435           11.90
  getIncomingSet   1111          833             232            5.32


5 November 2013
---------------
Remeasure after ripping out the AtomSpaceAsync wrapper.  Basically, expect
the atomspace and atomtable performance to be nearly identical (there are
still some differences and minor additinal layers, but they're mosty the
same).  There is no AtomSpaceImpl any more, so not measured.

Summary:
 -- AtomTable is not as good as the April 1 results; which are 2x to 2.5x
    faster than below.  The primary reason for this is the use of
    std::shared_ptr for all pointers.  Clearly, moving to garbage collection
    seems to be the right thing to do, long-run.

 -- AtomSpace is 6x to 15x faster. This is due to the removal of the
    excessive data copying of AtomSpaceAsync, as well as less locking
    for most operations.

 -- We are not measuring threaded performance here, but that should also
    much much better, maybe in the 20x-50x range, since the AtomSpaceAsync
    had a single lock and thus huge lock contention.  Now, most lock
    contention is gone, except for atomtable operations (all getHandleSet
    calls require index lookups and so will contend).

                   -A -X         -A          -A -g
   test           AtomTable    AtomSpace    Scheme
   name           K-ops/sec    K-ops/sec   K-ops/sec
   ----           ---------    ---------   ---------
  noop             5000        5000
  addNode           196         185
  addLink            87          78.1
  getType          1000         769
  getTV             769         833
  setTV             555         455
  getHandleSet        0.471       0.426
  getNodeHandles     95.2        87.0
  getOutgoingSet    769         588
  getIncomingSet    526         555
  removeAtom        161         156


22 January 2014
---------------
Remeasure, because locks had to be added to the truth-value getters.
Upshot: adding locks to the getTV path did not affect performance.
The setTV path got faster, probably due to cleaner impl.

Significant improvements in getIncoming/OutgoingSet ... not sure why.

Big drop in getNodesHandles, don't know why.


                   -A -X         -A          -A -g
   test           AtomTable    AtomSpace    Scheme
   name           K-ops/sec    K-ops/sec   K-ops/sec
   ----           ---------    ---------   ---------
  noop            10000        3333
  addNode           217          93.5
  addLink            88          54.3
  getType          1000         833
  getTV             769         833
  setTV             769         476
  getHandleSet        0.423       0.401
  getNodeHandles     41.8        30.5
  getOutgoingSet    833         666
  getIncomingSet    714         555
  removeAtom        145         130


7 March 2014
------------
Due to bug #524, scheme was always being interpreted, never compiled.
The previous commit fixes this, the setting #:compile? #t on
eval-string.  This should improve scheme performance.  Does it?
No, it des NOT. Gack. But of course. Compiling every time is just
going to slow everything down. Really, we should compile just once.
and measure the compiled code. Gack.  This needs a new benchmark...


                      -A -g
   test              compile
   name             K-ops/sec
   ----             ---------
  noop                 inf
  addNode              14.3
  addLink               6.67
  getType               0.826
  getTV                 2.04
  setTV                 1.92
  getOutgoingSet        1.92
  getIncomingSet        1.49
  removeAtom            0.392

                     27 Oct      -g       -G -r100   -G -r100
   test               2013      memo       interp     compile
   name            K-ops/sec   K-ops/sec  K-ops/sec  K-ops/sec
   ----            ---------   ---------  ---------  ---------
  noop                  inf      inf         inf
  addNode              8.93      9.61       10.7
  addLink              7.52      7.82        5.76
  getType              7.58      7.81       12.2
  getTV                6.37      8.62       13.4
  setTV                7.63      7.81        7.34
  getOutgoingSet      11.90     13.9        13.2
  getIncomingSet       5.32      8.62       12.6
  removeAtom            -       10.4        10.6

Comparing today's interpreted measurements to those from Oct 2013, looks
like everything improves.  The improvements are all due to the faster
underlying atomspace.

8 March 2014
------------
Again.  New flags:
 -g -M is now same as old -g : it runs scheme, and memoizes (memoization
       is run outside the timing loop).
 -g -C run scheme, and compile (compilation is done outside of timing loop)
 -g run scheme, raw, straight up interpretation: no memo, not compile.

                  previous     -g -M       -g         -g -C
   test           memoize     memoize     interp     compile
   name          K-ops/sec   K-ops/sec   K-ops/sec  K-ops/sec
   ----          ---------   ---------   ---------  ---------
  noop               inf         inf       inf         inf
  addNode           9.61         10.1       6.04        8.62
  addLink           7.82         6.80      2.36        7.24
  getType           7.81         6.85      4.69        7.41
  getTV             8.62         8.13      5.61        6.94
  setTV             7.81         7.25      3.73        7.46
  getOutgoingSet   13.9          6.41      4.75        7.12
  getIncomingSet    8.62         5.65      4.70        6.25
  removeAtom       10.4          7.87      4.19        5.15

In the above, "previous" is the column copied from above, yesterday.
It should be identical to -g -M but its not.  Today's runs seem a
lot slower.  There's a huge variability in reported times, run-to-run.
I don't like this failure to reproduce. I don't understand it.
By contrast, most of the other runs don't have this huge variability,
they are very consistent run to run.  Makes me think that there is
some cache/tlb invalidation that is dominating this.


                -g -M -r100    -g -r100   -g -C -r100    -A
   test           memoize       interp      compile    AtomSpace
   name          K-ops/sec     K-ops/sec   K-ops/sec   K-ops/sec
   ----          ---------     ---------   ---------   ---------
  noop               inf         inf          inf
  addNode           37.0        10.7         37.1         89.8
  addLink           57.3         3.32        67.0         58.1
  getType          102          11.8        128          833
  getTV            152          13.0        227          833
  setTV            128           7.25       203          625
  getOutgoingSet   217          12.6        288          697
  getIncomingSet   172          12.7        242          666
  removeAtom        69.4        10.7         74.6        130


Now, the above are a lot more interesting.   First, look at the -g -r100
column, and compare it to the -g column from the previous table.  The
difference between these two is the cost of entering and exiting guile.
The plain -g column enters guile, does one op, and exists.  The -r100
column enters guile, does 100 ops, and then exits.

The memoized and compiled columns should be compared to the interpreted
column: this shows exacly how painfully slow the interpreter is.  The
fact that the compiled and memoized columns are quite close to one
another illustrates that there's really not much going on in the
bindings.  For contrast, the last column shows the atomspace
performance. (repeated the measurement here, but it seems same as
before).

To summarize:
 1) the scheme bindings are pretty "thin"
 2) There's a huge overhead from using the scheme interpreter, as opposed
    to running compiled (or even memoized) code.
 3) There's a huge overhead to enter and exit the scheme subsystem.


So: there are two distinct costs:
 A) Cost of calling a C++ smob function, from scheme.  The above numbers
    suggest that the ballpark cost of this is about 2uS or 3uS
    (getOutgoingSet, getTV) but sometimes much worse: 7uS for getType,
    and 15 uS for addNode. This suggests severe cache-contention issues.

 B) Cost of calling scheme from C++. This seems to take about 175uS and
    sometimes much worse: 300uS to 400uS.  Perhaps this could be worked
    around by having another thread on standby:  linux thread-context
    switching should run about about 5uS per switch ...

Caution: some of the above conclusions are either misleading, or the
entire performance profile changed radically for guile-2.2.  Based on
direct instrumented measurements (see immediately below) it looks like
61% of the total time is spent getting from scm_c_catch, getting through
the evaluator, and finally calling SchemeSmob::ss_new_node(). Then the
SchemeSmob::ss_new_node() code takes another 28%, and so everything
else, viz, getting from C++ to scm_c_catch(), and then returning back to
c++ only takes 11% of the total CPU time.  Thus, at least for guile-2.2,
the primary bottleneck is really scm_c_eval().  Ergo, compiled code
really does look like the only viable solution....


=================================================================

22 Jan 2015: measurements on fanny.  fanny is a differnt machine than
the above.  Also: measurements are done with guile-2.2 from a December
2014 git pull.  So these numbers are not directly comparable to the
above.

enter scm_with_guile() takes 1.3 uSec
(viz, get from c++, and pass through scm_with_guile() takes 1.3 uSec)
return from scm_with_guile() takes 0.43 uSec
SchemeSmob::scm_to_handle() takes 0.20 uSec

do_scm_eval_str("(ConceptNode \"object_42\")") takes 66.5 uSec
scm_c_catch of above takes 65uSec

from scm_c_catch to ss_new_node: 41.2 uSec
ss_new_node(): 18.7 uSec
return from ss_new_node to scm_c_catch: 4.0 uSec

Conclude: the bottleneck is currently having guile interpret the
incoming string, decide what to do with it, and then call the smob
handler.  Yes, we are nickel-n-dimed in other places, but that one
is 2/3rds of the total time, and its essentially not tunable within
opencog.

=====================================================================
23 January 2015:
Above measurements partly invalidated; ss_new_node is now about 20%
faster after some rework.

Where is the time being spent?
Consider the program:
	(define (lop n)
		(begin
			(ConceptNode (number->string n))
			(if (< 0 n) (lop (- n 1)) #f) ))

and then perform timing measurements on:
	(lop 50000)

Find that 61% of total time is spent in ss_new_node and 39% is spent
in guile itself.  The above is effectively memoized. If it is compiled,
viz.
	(compile `(define (lop n) ...) #:env (current-module))

then find that 69% of time in ss_new_node 31% of time in guile.
----
Of the time spent in ss_new_node, about 48% is spent in
AtomSpace::addNode() and the rest is in preparing to call it ...

breakdown:
	43% in verify
	1% in get atomspace
	48% in AtomSpace::addNode()
	1% in get tv, av
	9.5% in handle_to_scm()

Breakdon of verify:
	1%  verify_atom_type()
	43% in verify_string()   ouuuuuch

of verify_string():
	41% in scm_to_locale_string() ouch ...

Wow... scm_to_utf8_string() is 10x faster than scm_to_locale_string()
and scm_i_string_chars() is another 4x faster.  Yowwww

==================================================================
24 January 2015:
Revised numbers:
On "fanny", Linux Mint Rebecca (Ubuntu 14.04) gcc 4.8.2 guile-2.2

                -g -M -r100    -g -r100   -g -C -r100    -A
   test           memoize       interp      compile    AtomSpace
   name          K-ops/sec     K-ops/sec   K-ops/sec   K-ops/sec
   ----          ---------     ---------   ---------   ---------
  noop               inf         inf          inf       1915
  addNode          101          17.7         97.2        144.4
  addLink          155           5.83       161           93.3
  getType          213          22.9        207          626
  getTV            230          23.6        243          582
  setTV            165          13.2        201          530
  getOutgoingSet   252          24.4        242          596
  getIncomingSet   220          23.8        222          487
  removeAtom        90.2        20.1         77.7        147

Observations:

-- addLink is faster for the scheme, than the native C++.  ... why?
   some bizarre cache contention ???

==================================================================
15 March 2015:
Revised numbers:
On "fanny", Linux Mint Rebecca (Ubuntu 14.04) gcc 4.8.2 guile-2.2
guile (GNU Guile) 2.1.0.305-e7097-dirty
This is after re-working the rather old Index design, so as to store
AtomPtr's instead of UUID's. Expecting this to improve addNode and
addLink. The improvements to the atom getters are a fallout of previous
work for the last several months.

                -g -M -r100    -g -r100   -g -C -r100    -A
   test           memoize       interp      compile    AtomSpace
   name          K-ops/sec     K-ops/sec   K-ops/sec   K-ops/sec
   ----          ---------     ---------   ---------   ---------
  noop               inf         inf          inf       1915
  addNode          121          19.3        104          183
  addLink          232           6.08       262           95.1
  getType          243          25.3        383         1720
  getTV            441          25.5        477         1486
  setTV            249          13.1        249          863
  getOutgoingSet   514          24.6        443         1532
  getIncomingSet   418          24.8        447         1117
  removeAtom       107          21.4        114          161
  getNodeHandles                                          34.3

Interpreter entry/exit overhead, guile vs. python:
The below measures mostly the cost of entering and existing the
interpreters: i.e. this measures the cost of entering the interpreter,
doing exactly one atom operation, and then exiting the interpreter.
By comparison, the figures above measure 100 ops after entering the
interpreter (or VM, in case of guile).

Also: some prelim results for looped python. The test case needs to be
hacked to get additional numbers out of it... memoization does not work
for python, either, can't tell why...

                 guile -g      python -c   python -c -r100
   test           interp        interp       interp
   name          K-ops/sec     K-ops/sec    K-ops/sec
   ----          ---------     ---------    ---------
  noop             inf          inf
  addNode           15.0          7.03        47.7
  addLink            5.58         6.14
  getType           17.4          7.73
  getTV             17.6          7.80
  setTV             10.1          6.58
  getOutgoingSet    17.2          7.04
  getIncomingSet    16.1          7.15
  removeAtom        15.1         crash

======================================================================
19 March 2015:

On "fanny", replaced AtomPtr in the AtomTable indexes with Atom*.
This should improve atom insert and remove performance. It does seem
to, but not very much.

                 -A Atom*     AtomPtr
   test          AtomSpace
   name          K-ops/sec
   ----          ---------   --------
  addNode          195         183
  addLink          101          95.1
  removeAtom       170         161


======================================================================
01 April 2015:

Updated the benchmark and getHandlesByType to use .reserve on the HandleSeq
to eliminate unnecessary copies of the Handles during resize.

This resulted in the following improvement:

Before:
                      -m getHandlesByType
   test               AtomSpace
   name               K-ops/sec
   ----               ---------
  getHandlesByType    0.320

After:
                      -m getHandlesByType
   test               AtomSpace
   name               K-ops/sec
   ----               ---------
  getHandlesByType    0.439

======================================================================
2 October 2015

On "fanny", after removing UUID's from handles.

                 old (March)  new (master)  new (de-uuid)
                    -A            -A           -A
   test           AtomSpace     AtomSpace    AtomSpace
   name           K-ops/sec     K-ops/sec    K-ops/sec
   ----           ---------     ---------    --------
  noop             1915          1780         1821
  getType          1720          1391         1345
  getTV            1486          1028         1031
  setTV             863           575          574
  getOutgoingSet   1532           832          836
  getIncomingSet   1117           642          634
  addNode           183           156          160
  addLink            95.1          84.3         73.5
  removeAtom        161           172          166



The "old" column is a cut-n-paste from the March 2015 results above.
The "new (master)" column is the git-pull from 1 October 2015.
The "new (de-uuid)" column is the de-uuid branch thate removes the
    UUID's from the handle.

The measurement for the gets has to be done with -n1M to get valid
values; the default -n of 100K is too small.


Observations:
* The getType, getTV, setTV, getIn/OutSet saw reductions of about
  half since March.  Why?  Well, comparing the March No-op results to
  to these suggests that these were near the limit of measurability (as
  currently done, which is poorly). These functions could-be/were rate
  limited by the speed of derefrencing AtomPtr.  Why this changed is ...
  unknown to me.  A git bisect would be useful. XXXX WTF. If measured
  one at a time, i.e. -m getIncomingSet, instead of in bulk, -A then
  the results are on parity. So .. is something wrong with the -A flag?
  What could possibly be different? The remeasured results below.

* The addNode and removeAtom operations are unchanged by the de-uuid
  process.  That addLink got slower is dissappointing, but may be due
  to the fact that, in the past, Handle comparison was done by directly
  comparing UUID's in the Handles, whereas now, it must be done by
  fetching them from atoms.

* That all three addNode addLink and removeAtom are in the same ballpark
  indicates that the primary bottleneck here is the update of the
  atomspace indexes (either add or remove in these).


Below: same as above, except remeasured with -m testName -n 2000000
Big WTF as to  why this differs from -A

                 new (master)  new (de-uuid)
                     -A           -A
   test            AtomSpace    AtomSpace
   name            K-ops/sec    K-ops/sec
   ----            ---------    --------
  noop              1744         1802
  getType           1654         1675
  getTV             1495         1451
  setTV              744          726
  getOutgoingSet    1480         1520
  getIncomingSet    1149         1147

Its all broken. Remeasure, below.

======================================================================
2 October 2015

ProtoAtom testing.
Implementing the ProtoAtom requires that some of the Handle operators,
for casting to AtomPtr and for operator->() are no longer in he header
file. Does this impact performance? Lets see...

                   de-uuid      -flto -O3     -02
                     -A           -A           -A
   test
   name            K-ops/sec    K-ops/sec   K-ops/sec
   ----            ---------    ---------   ---------
  noop              1821         1771         1783
  getType           1345         1327         1349
  getTV             1031         1024         1025
  setTV              574          544          538
  getOutgoingSet     836          814          791
  getIncomingSet     634          625          620
  addNode            160          141          138
  addLink             73.5         46.4         46.8
  removeAtom         166          129          128

de-uuid column:  copied from above; its the current mainline.
-flto -O3:  CMakefile enables gcc -O3 -flto flags as well as the
            the ProtoAtom changes to Handle.h
-O2 column: CMakefile enables gcc -O2 only ... but with ProtoAtom.

Conclusions:
* ProtoAtom has a strong impact on the AddLink performance, and maybe
  a 13% hit to AddNode and 23% hit to removeAtom.  Meanwhile -flto is
  essentially invisible. This is surprising.  One may have thought that
  the get* functions would take a hit from the lack of operator->()
  inlining, which the -flto would fix. Well, no hit and no fix.
  Meanwhile. addLink does get hit. Why?  I think this has something
  to do with index insertion, maybe due to bad std::less<Handle>
  performance??

======================================================================
3 October 2015

Clearly the benchmark has been badly designed for too long.  So fix
this.  All inner loop mesurements are now repeated 2K times, by default.
The current results are:

                   broken         fixed
                    -A             -A
   test           AtomSpace     AtomSpace
   name           K-ops/sec     K-ops/sec
   ----           ---------     ---------
  noop             1821           1e6
  getType          1345          75.5K
  getTV            1031           4166
  setTV             574           1113
  getOutgoingSet    836           7555
  getIncomingSet    634           2276
  addNode           160            149
  addLink            73.5           70.1
  removeAtom        166            188

broken column: copied from above, measured with the broken benchmark.
fixed column: measured with the fixed benchmark.

Comments:
The get* numbers are much much higher, because the old test was
mis-measuring these; they were under a microsecond, so the call to
clock() was giving spurious measurements. The actual performance is
now revealed. Its roughly equal to what one would get from the
broken column, if one took the reciprocal, subtracted the "noop",
and took the reciprocal, again. Basically, the "broken" numbers had
included a hefty overhead from calling clock(), an had not been
correctly normalized.

The removeAtom numbers are faster, because only 3/4ths the atomspace
gets removed now. The change in addNode and addLink is unclear.

======================================================================
3 October 2015

How fast is HandleSeq, really?

atomspace_bm -

   count             1            2           3            4
   rate           M-ops/sec    M-ops/sec   M-ops/sec    M-ops/sec
   ----           ---------    ---------   ---------    ---------
  push_back         7.54         3.27        1.96         1.88
  emplace_back      7.26         3.35        1.96         1.87
  reserve           7.66         6.01        4.75         4.13

count: the number of handles that are pushed/emplaced back.

push_back: call the push-back method
     example: HandleSeq oset; oset.push_back(ha); oset.push_back(hb);

emplace-back: call the emplace_back method

reserve: create vector of fixed size, then assign directly.
     example: HandleSeq oset(2); oset[0] = ha; oset[1] = hb;

Looks like direct assignment is a winner!

======================================================================
 15 Oct 2015

Again, ProtoAtom.

                  AtomPtr         Atom*        ProtoAtom*
                    -A             -A             -A
   test           AtomSpace     AtomSpace      AtomSpace
   name           K-ops/sec     K-ops/sec      K-ops/sec
   ----           ---------     ---------      ---------
  noop              1e6           1e6            2e6
  getType          75.5K         78.6K           16.5K
  getTV             4166          4361            4732
  setTV             1113          1209            1245
  getOutgoingSet    7555          7332            6821
  getIncomingSet    2276          2335            2267
  addNode            149           153             153
  addLink             70.1          73.4            54.1
  removeAtom         188           191             175


AtomPtr column: copied from above
Atom* column:   using bool atoms_less(const Atom*, const Atom*); in
                Handle.h (used to be AtomPtr)
ProtoAtom*:     using bool atoms_less(const ProtoAtom*, etc...)

Conclude: switching to * from Ptr for handle compares helps. But AddLink
   still hurts; it hurts just a bit less.

======================================================================

4 Feb 2016
----------
ProtoAtom work .. how much does a cast really cost?
i.e. a cast from Handle to NodePtr or LinkPtr ?

atomspace_bm -m noop -m getType -m pointerCast -m getOutgoingSet

                  previous      NodeCast        LinkCast
   name           K-ops/sec     K-ops/sec      K-ops/sec
   ----           ---------     ---------      ---------
  noop              1e6         889K             864K
  getType          75.5K         72.0K            72.0K
  pointerCast        -            6375             7354
  getOutgoingSet    7555          7646             7797

previous: copied column from above.

NodeCast: perform NodeCast only.

LinkCast: perform LinkCast only.

Comments: we expect the pointerCast and the getOutgoingSet values to be
nearly identical, since getOutgoingSet is just a cast, followed by a
very simple method call.  The NodeCast and Link Cast numbers might
differ, but not much, due to the different ratios of links and nodes in
the sample set.

Ergo, the cost of getOutgoingSet is dominated by the LinkCast!  If we
get rid of it, then what happens?  It goes up to 44.1M-ops/sec! Woww!


New baseline is then
                  previous      ProtoAtom
   name           K-ops/sec     K-ops/sec
   ----           ---------     ---------
  noop              1e6          1.7e6
  getType          75.5K         76.7K
  getTV             4166          4291
  setTV             1113          1133
  getOutgoingSet    7555         38.5K
  getIncomingSet    2276          2265
  addNode            149           145
  addLink             70.1          67.9
  removeAtom         188           187

previous: the situation before protoatoms; copied from above.

ProtoAtom: this branch, including recent work on avoiding smart-pointer
    casts.

=====================================================================

4 Feb 2016
----------
New guile baseline. Fanny.  This includes the ProtoAtom code.


                -g -M -r100    -g -r100   -g -C -r100    -A
   test           memoize       interp      compile    AtomSpace
   name          K-ops/sec     K-ops/sec   K-ops/sec   K-ops/sec
   ----          ---------     ---------   ---------   ---------
  noop             2e6          2e6         2e6         1.5e6
  getType          393          18.3        177        78.0K
  getTV            380          19.7        218         4261
  setTV            230          11.2        122         1129
  getIncomingSet   359          20.5        119         2250
  getOutgoingSet   340          20.4        118        38.6K
  addNode          234          17.6         87.8        145
  addLink          282           5.02       224           67.5
  removeAtom         3.33        6.69        34.6        186

Remarks:
 * The memoize and interpreted numbers are a little worse than
   before. Not sure why.
 * The removeAtom number seems to be insane, but I cannot spot a
   bug right now.
 * How can it be possible that memoized addNode is faster than the
   C++ addNode? Isn't this logically impossible? Also, addLink...
 * The compiled numbers are half of what they used to be! Or even 1/3
   of what they used to be... And they are also worse than the
   memoized numbers, which should be impossbile.  WTF???
 * Now that we have correctly-measured AtomSpace numbers, the guile
   numbers are easily seen to be much worse than the C++ numbers.
 * The uniformity of numbers in the memoize column sugggests a
   bottleneck; I'm guessing its the ProtoAtomPtr->Handle cast.
 * This is not a very good benchmark, because it does not represent
   the way that people would "typically" program in scheme.

To summarize: this test is wonky, crazy; the numbers are bizzarely
inconsistent with expectations.

======================================================================

7 March 2016
------------

How fast is HandleSeq, really?

Revisited.

While working on the ODBC version of the new Edges table, since I can't
know how many rows there are since ODBC gives no way to know until you
reach the end of the rows using SQLFetch, I can't use the size and place
directly method, so I wanted to see if doing pre-reserve allocations was
worth the effort. This caused me to look at the existing atomspace_bm code
which did this analysis to see how much slower emplace_back was. So I
added calls to vector.reserve() to see if this would speed things up.

I created two new benchmark tests with calls to call vector.reserve(N)
before push_back and emplace_back.

The previous attempt to reserve was sizing the vector using the constructor.
This still caused push_back and emplace_back to allocate each time. For example,
sizing to 4 then doing 4 emplace_backs, for example would resize to 5, 6,
7, then 8. In contrast, the call to vector.reserve(N) changes only the storage
but not the vector size, so vector.reserve(4) followed by 4 emplace_backs or
push_backs results in only one memory allocation but 4 vector size changes.
It appears that all vectors reserve sufficient space for one element which
accounts for all five methods having essentially the same timing for a single
operation.

Using vector.reserve() makes both push_back and emplace_back essentially the
same speed as the 'reserve' test.

atomspace_bm -

   count                  1            2           3            4
   rate               M-ops/sec    M-ops/sec   M-ops/sec    M-ops/sec
   ----               ---------    ---------   ---------    ---------
  push_back             13.90         6.99        4.11         4.04
  push_back_reserve     14.24        11.79       10.01         8.54
  emplace_back          13.82         6.63        4.02         3.94
  emplace_back_reserve  13.96        11.18        9.66         8.78
  reserve               14.39        11.59        9.52         8.79

count: the number of handles that are pushed/emplaced back.

push_back: call the push-back method
  example:
    HandleSeq oset; oset.push_back(ha); oset.push_back(hb);

push_back_reserve: reserve count, then call the push-back method
  example:
    HandleSeq oset; oset.reserve(2); oset.push_back(ha); oset.push_back(hb);

emplace-back: call the emplace_back method
  example:
     HandleSeq oset; oset.emplace_back(ha); oset.emplace_back(hb);

emplace_back_reserve: reserve count, then call the emplace_back method
  example:
    HandleSeq oset; oset.reserve(2);  oset.emplace_back(ha); oset.emplace_back(hb);

reserve: create vector of fixed count size, then assign directly.
  example:
    HandleSeq oset(2); oset[0] = ha; oset[1] = hb;

So it appears that the big issue is avoiding the resizing of the vector
which involves both memory allocations and copies into the new memory.
The differences between push_back_reserve, emplace_back_reserve, and
reserve now appear to be smaller than the jitter noise of the benchmark
timings.

Above is for Ubuntu Trusty and the default gcc therein.

======================================================================

3 Nov 2016
------------
New core baseline. Fanny.  This baseline measures perf after converting
atomtable to use hashes (and then fixing bugs related to that, a week
later).  The hashes are expected to improve performance of atom
insertion and deletion.

compiler: gcc version 6.2.0

                     -A            -A
   test            AtomSpace       Feb
   name            K-ops/sec      2016         Comments
   ----            ---------      ----      ----------------------------
  noop              2.11e6       1.5e6      ?  compiler ?
  getType          96.6K        78.0K       +24% faster -- compiler?
  getTV             4205         4261       -1% slower -- cache effect?
  setTV             1182         1129       +5% faster -- cache effect?
  pointerCast       7279
  getIncomingSet    2192         2250       -3% slower -- cache effect?
  getOutgoingSet   36.2K        38.6K       -6% slower -- ?
  addNode            201          145       +39% faster
  addLink             81.9         67.5     +21% faster
  removeAtom         279          186       +50% faster

Remarks:
 * Expected that only addNode, addLink, removeAtom would change.
   Other changes are possibly due to compiler differences, or due
   to cache-alignment effects?
 * Hashing does seem to improve atomtable performance, though not
   as much as might be guessed.

======================================================================

3 Nov 2016
----------

HandleMap access time.
----------------------
Wow.  I was using try...catch semantics under the assumption that
this is fast, but it turns out that stack unwinding is very expensive.
Thus, catch should only be used for those cases tha trigger
infrequently.

PatternMatchEngine.cc line 777: var_grounding.at(hp)
time ./opencog/benchmark/profile_bindlink

0m12.820s
0m12.732s
0m13.178s
0m12.872s
0m13.351s

PatternMatchEngine.cc line 777: var_grounding.find(hp);
time ./opencog/benchmark/profile_bindlink

0m7.209s
0m7.240s
0m7.400s
0m7.168s
0m7.287s

That one change almost doubles the performance!!

try again: replace try by find at
PatternMatchEngine.cc line 1558

0m5.506s
0m5.638s
0m5.584s
0m5.666s
0m5.717s

PatternMatchEngine.cc line 100

0m3.595s
0m3.689s
0m3.498s
0m3.660s
0m3.712s

Awesome!

Now remove all the pattern matcher print statements...

0m3.444s
0m3.353s
0m3.391s
0m3.388s
0m3.479s

Less of a hit, but still significant.

======================================================================

11 Nov 2016
------------
New core baseline. Fanny.  This baseline measures perf after removing
UUID's from the atoms (and thus, removing the UUID index from the
atomtable.) This should make atom insertion and deletion faster.

compiler: gcc version 6.2.0

                     -A          -A            -A
   test              today     last week       Feb
   name            K-ops/sec   K-ops/sec      2016         Comments
   ----            ---------   ---------      ----      -----------------
  noop              1.76e6      2.11e6       1.5e6      cache effects
  getType          79.1K       96.6K        78.0K       back to before
  getTV             4099        4205         4261
  setTV             1217        1182         1129
  pointerCast       7561        7279
  getIncomingSet    2272        2192         2250       back to before
  getOutgoingSet   43.6K       36.2K        38.6K       wow. 20% faster.
  addNode            231         201          145       15% faster
  addLink             88.3        81.9         67.5      8% faster
  removeAtom         431         279          186       54% faster !!

Remarks:
* Removal of the UUID make the atoms slightly smaller - about 5% or 10%
  depending on the atom.  So cache line alignments will be different.
* Variation of getType performance indicatie of the caching effect.
* Variation of getOutgoingSet unexpected: caching effect?
  Maybe something to do with cache alignment of Handles and atoms?
* Improvement of addNode, addLink and removeAtom probably explainable
  by the removal of the atom-UUID index.
* addLink is still slow, due to all the stupid cloning & etc.

======================================================================

29 Dec 2016
-----------
New core baseline. Fanny.  This baseline measures perf after removing
AttentionValue's from the atoms (and thus, removing signal overuse in
the AttentionBank.) This should make atom insertion and deletion faster.

compiler: gcc version 6.2.1

                     -A          -A           -A
   test            11 Nov       today         Feb
   name            K-ops/sec   K-ops/sec      2016         Comments
   ----            ---------   ---------      ----      -----------------
  noop              1.76e6      2.20e6       1.5e6      cache effects
  getType          79.1K       82.3K        78.0K       ??
  getTV             4099        4109         4261
  setTV             1217        1243         1129
  pointerCast       7561        8236                    ??
  getIncomingSet    2272        2270         2250
  getOutgoingSet   43.6K       47.2K        38.6K       ??
  addNode            231         305          145       32% faster
  addLink             88.3       103         67.5       17% faster
  removeAtom         431         559          186       30% faster !!

Remarks:
* Variation of getOutgoingSet unexpected: it improves on the previous
  unexpected improvement... can this be because the Atom got smaller
  again?
* Improvement in getType and pointerCast also unexpected.
* Improvement in addNode addLink removeAtom expected, because of
  refactoring of very inefficient AttentionBank.
